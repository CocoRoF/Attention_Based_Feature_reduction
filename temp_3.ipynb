{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":305,"status":"ok","timestamp":1694584860067,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"B5i89UMJS8sv"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from util.module import *\n","from util.utility import *\n","import lightgbm as lgb\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","df = pd.read_csv('./Data/house-prices-advanced-regression-techniques/train.csv')\n","numeric_df = df.select_dtypes(include=['int', 'float'])\n","\n","numeric_df = numeric_df.dropna(axis=0)\n","numeric_df.reset_index(inplace=True, drop=True)\n","test_df_x = numeric_df.iloc[:, 1:23]\n","test_df_y = numeric_df.iloc[:, -1]\n","\n","array_df = np.array(test_df_x)\n","fa = Factor_attention(array_df, dim_information=512)\n","fa.col_to_vec(threshold = 0.5)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"elapsed":706,"status":"error","timestamp":1694585118786,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"CfnxVaqOIEpK","outputId":"feec3ef8-dfb7-4f0f-964d-75b51ded0ead"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [5/500], Loss: 32.1943\n","Epoch [10/500], Loss: 30.8610\n","Epoch [15/500], Loss: 29.9103\n","Epoch [20/500], Loss: 29.3441\n","Epoch [25/500], Loss: 29.6086\n","Epoch [30/500], Loss: 29.3994\n","Epoch [35/500], Loss: 29.2991\n","Epoch [40/500], Loss: 29.4329\n","Epoch [45/500], Loss: 29.4978\n","Epoch [50/500], Loss: 29.4378\n","Epoch [55/500], Loss: 29.2647\n","Epoch [60/500], Loss: 29.1651\n","Epoch [65/500], Loss: 29.0940\n","Epoch [70/500], Loss: 29.1160\n","Epoch [75/500], Loss: 29.0421\n","Epoch [80/500], Loss: 29.0559\n","Epoch [85/500], Loss: 28.9754\n","Epoch [90/500], Loss: 28.9030\n","Epoch [95/500], Loss: 28.8107\n","Epoch [100/500], Loss: 28.8097\n","Epoch [105/500], Loss: 28.5422\n","Epoch [110/500], Loss: 28.4845\n","Epoch [115/500], Loss: 28.3905\n","Epoch [120/500], Loss: 28.1422\n","Epoch [125/500], Loss: 27.8921\n","Epoch [130/500], Loss: 27.9182\n","Epoch [135/500], Loss: 27.9072\n","Epoch [140/500], Loss: 27.4176\n","Epoch [145/500], Loss: 27.4231\n","Epoch [150/500], Loss: 27.1998\n","Epoch [155/500], Loss: 26.5910\n","Epoch [160/500], Loss: 26.7667\n","Epoch [165/500], Loss: 26.6624\n","Epoch [170/500], Loss: 26.6097\n","Epoch [175/500], Loss: 26.5676\n","Epoch [180/500], Loss: 26.6864\n","Epoch [185/500], Loss: 26.4590\n","Epoch [190/500], Loss: 26.6590\n","Epoch [195/500], Loss: 26.4147\n","Epoch [200/500], Loss: 26.5081\n","Epoch [205/500], Loss: 26.4987\n","Epoch [210/500], Loss: 26.4166\n","Epoch [215/500], Loss: 26.3572\n","Epoch [220/500], Loss: 26.4157\n","Epoch [225/500], Loss: 26.5223\n","Epoch [230/500], Loss: 26.4308\n","Epoch [235/500], Loss: 26.3757\n","Epoch [240/500], Loss: 26.4531\n","Epoch [245/500], Loss: 26.4588\n","Epoch [250/500], Loss: 26.3739\n","Epoch [255/500], Loss: 26.4231\n","Epoch [260/500], Loss: 26.3924\n","Epoch [265/500], Loss: 26.4085\n","Epoch [270/500], Loss: 26.4818\n","Epoch [275/500], Loss: 26.4941\n","Epoch [280/500], Loss: 26.4148\n","Epoch [285/500], Loss: 26.3213\n","Epoch [290/500], Loss: 26.3878\n","Epoch [295/500], Loss: 26.4453\n","Epoch [300/500], Loss: 26.4261\n","Epoch [305/500], Loss: 26.5294\n","Epoch [310/500], Loss: 26.5179\n","Epoch [315/500], Loss: 26.4040\n","Epoch [320/500], Loss: 26.5080\n","Epoch [325/500], Loss: 26.4122\n","Epoch [330/500], Loss: 26.3987\n","Epoch [335/500], Loss: 26.4038\n","Epoch [340/500], Loss: 26.3702\n","Epoch [345/500], Loss: 26.3382\n","Epoch [350/500], Loss: 26.4325\n","Epoch [355/500], Loss: 26.4038\n","Epoch [360/500], Loss: 26.3138\n","Epoch [365/500], Loss: 26.3123\n","Epoch [370/500], Loss: 26.3615\n","Epoch [375/500], Loss: 26.3354\n","Epoch [380/500], Loss: 26.2840\n","Epoch [385/500], Loss: 26.2853\n","Epoch [390/500], Loss: 26.3241\n","Epoch [395/500], Loss: 26.3538\n","Epoch [400/500], Loss: 26.2701\n","Epoch [405/500], Loss: 26.3236\n","Epoch [410/500], Loss: 26.3123\n","Epoch [415/500], Loss: 26.2892\n","Epoch [420/500], Loss: 26.2685\n","Epoch [425/500], Loss: 26.2717\n","Epoch [430/500], Loss: 26.2817\n","Epoch [435/500], Loss: 26.2774\n","Epoch [440/500], Loss: 26.2817\n","Epoch [445/500], Loss: 26.2456\n","Epoch [450/500], Loss: 26.3006\n","Epoch [455/500], Loss: 26.2712\n","Epoch [460/500], Loss: 26.2657\n","Epoch [465/500], Loss: 26.3523\n","Epoch [470/500], Loss: 26.2713\n","Epoch [475/500], Loss: 26.3151\n","Epoch [480/500], Loss: 26.3672\n","Epoch [485/500], Loss: 26.3397\n","Epoch [490/500], Loss: 26.2831\n","Epoch [495/500], Loss: 26.4987\n","Epoch [500/500], Loss: 26.2988\n"]}],"source":["model = Attention(n_factor= fa.n_factors, info_dim = fa.dim_info)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","num_epochs = 500\n","for epoch in range(num_epochs):\n","    \n","    reconstructed = model(fa)\n","    loss = pearson_correlation_coefficient_loss_function(reconstructed)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    torch.autograd.set_detect_anomaly(True)\n","\n","    if (epoch+1) % 5 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1121, 12])"]},"execution_count":133,"metadata":{},"output_type":"execute_result"}],"source":["model.total_result.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# X = np.array(numeric_df.iloc[:, 1:23])\n","X = torch.Tensor.cpu(model.total_result).detach().numpy()\n","Y = np.array(numeric_df.iloc[:, -1])\n","\n","# 데이터 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","# Min-Max 정규화\n","scaler_X = MinMaxScaler()\n","X_train = scaler_X.fit_transform(X_train)\n","X_test = scaler_X.transform(X_test)\n","\n","scaler_Y = MinMaxScaler()\n","y_train = scaler_Y.fit_transform(y_train.reshape(-1, 1)).ravel()\n","y_test = scaler_Y.transform(y_test.reshape(-1, 1)).ravel()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 567 candidates, totalling 1701 fits\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000172 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1587\n","[LightGBM] [Info] Number of data points in the train set: 896, number of used features: 11\n","[LightGBM] [Info] Start training from score 0.208582\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Best parameters found:  {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 50, 'subsample': 0.5}\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","RMSE with best parameters: 45646.09259521249\n"]}],"source":["# LightGBM 회귀 모델 객체 생성\n","lgb_model = lgb.LGBMRegressor()\n","\n","# 탐색할 파라미터 설정\n","param_grid = {\n","    'n_estimators': [50, 100, 200],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'max_depth': [10,13,15,17,20,25,30],\n","    'colsample_bytree': [0.5, 0.7, 1.0],\n","    'subsample': [0.5, 0.7, 1.0]\n","}\n","\n","# GridSearchCV 객체 생성\n","grid_search = GridSearchCV(lgb_model, param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# 최적의 파라미터 출력\n","print(\"Best parameters found: \", grid_search.best_params_)\n","\n","# 최적의 파라미터로 모델 훈련\n","best_lgb_model = grid_search.best_estimator_\n","\n","# 예측 수행\n","y_pred = best_lgb_model.predict(X_test)\n","\n","# 예측값을 원래의 스케일로 변환\n","y_pred_original = scaler_Y.inverse_transform(y_pred.reshape(-1, 1)).ravel()\n","\n","# 원래 스케일의 y_test 값도 변환\n","y_test_original = scaler_Y.inverse_transform(y_test.reshape(-1, 1)).ravel()\n","\n","# RMSE 계산 및 출력\n","rmse = mean_squared_error(y_test_original, y_pred_original, squared=False)\n","print(f\"RMSE with best parameters: {rmse}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 567 candidates, totalling 1701 fits\n","Best parameters found:  {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50, 'subsample': 1.0}\n","RMSE with best parameters: 44700.25190928062\n"]}],"source":["# XGBoost 회귀 모델 객체 생성\n","xgb_model = xgb.XGBRegressor()\n","\n","# 탐색할 파라미터 설정\n","param_grid = {\n","    'n_estimators': [50, 100, 200],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'max_depth': [10,13,15,17,20,25,30],\n","    'colsample_bytree': [0.5, 0.7, 1.0],\n","    'subsample': [0.5, 0.7, 1.0]\n","}\n","\n","# GridSearchCV 객체 생성\n","grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# 최적의 파라미터 출력\n","print(\"Best parameters found: \", grid_search.best_params_)\n","\n","# 최적의 파라미터로 모델 훈련\n","best_xgb_model = grid_search.best_estimator_\n","\n","# 예측 수행\n","y_pred = best_xgb_model.predict(X_test)\n","\n","# 예측값을 원래의 스케일로 변환\n","y_pred_original = scaler_Y.inverse_transform(y_pred.reshape(-1, 1)).ravel()\n","\n","# 원래 스케일의 y_test 값도 변환\n","y_test_original = scaler_Y.inverse_transform(y_test.reshape(-1, 1)).ravel()\n","\n","# RMSE 계산 및 출력\n","rmse = mean_squared_error(y_test_original, y_pred_original, squared=False)\n","print(f\"RMSE with best parameters: {rmse}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
