{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import dataloader\n",
    "from util import infogain\n",
    "from util import cluster\n",
    "from util import models\n",
    "from util.error_func import pearson_correlation_coefficient_loss_function\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataloader.data_load('boston')\n",
    "fa_result = infogain.Feature_infogain(x).FA()\n",
    "cluster_result = cluster.Cluster_Func(fa_result).cos_sim()\n",
    "input1, input2 = models.feature_combination(x, fa_result, cluster_result).subset_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/500], Loss: 7.5192\n",
      "Epoch [10/500], Loss: 7.4771\n",
      "Epoch [15/500], Loss: 7.5500\n",
      "Epoch [20/500], Loss: 7.5620\n",
      "Epoch [25/500], Loss: 7.5633\n",
      "Epoch [30/500], Loss: 7.5595\n",
      "Epoch [35/500], Loss: 7.5512\n",
      "Epoch [40/500], Loss: 7.5366\n",
      "Epoch [45/500], Loss: 7.5113\n",
      "Epoch [50/500], Loss: 7.4698\n",
      "Epoch [55/500], Loss: 7.4121\n",
      "Epoch [60/500], Loss: 7.3455\n",
      "Epoch [65/500], Loss: 7.2681\n",
      "Epoch [70/500], Loss: 7.1516\n",
      "Epoch [75/500], Loss: 6.8818\n",
      "Epoch [80/500], Loss: 6.0763\n",
      "Epoch [85/500], Loss: 6.1889\n",
      "Epoch [90/500], Loss: 6.1455\n",
      "Epoch [95/500], Loss: 6.1387\n",
      "Epoch [100/500], Loss: 6.0603\n",
      "Epoch [105/500], Loss: 6.0870\n",
      "Epoch [110/500], Loss: 6.0927\n",
      "Epoch [115/500], Loss: 6.0831\n",
      "Epoch [120/500], Loss: 6.1334\n",
      "Epoch [125/500], Loss: 6.1331\n",
      "Epoch [130/500], Loss: 6.0917\n",
      "Epoch [135/500], Loss: 6.0893\n",
      "Epoch [140/500], Loss: 6.1353\n",
      "Epoch [145/500], Loss: 6.1278\n",
      "Epoch [150/500], Loss: 6.0566\n",
      "Epoch [155/500], Loss: 6.0958\n",
      "Epoch [160/500], Loss: 6.1155\n",
      "Epoch [165/500], Loss: 6.1084\n",
      "Epoch [170/500], Loss: 6.1280\n",
      "Epoch [175/500], Loss: 6.1446\n",
      "Epoch [180/500], Loss: 6.1411\n",
      "Epoch [185/500], Loss: 6.1162\n",
      "Epoch [190/500], Loss: 6.1618\n",
      "Epoch [195/500], Loss: 6.1185\n",
      "Epoch [200/500], Loss: 6.1121\n",
      "Epoch [205/500], Loss: 6.1111\n",
      "Epoch [210/500], Loss: 6.0856\n",
      "Epoch [215/500], Loss: 6.1144\n",
      "Epoch [220/500], Loss: 6.0888\n",
      "Epoch [225/500], Loss: 6.0767\n",
      "Epoch [230/500], Loss: 6.0526\n",
      "Epoch [235/500], Loss: 6.0827\n",
      "Epoch [240/500], Loss: 6.0582\n",
      "Epoch [245/500], Loss: 6.0487\n",
      "Epoch [250/500], Loss: 6.0761\n",
      "Epoch [255/500], Loss: 6.0558\n",
      "Epoch [260/500], Loss: 6.0588\n",
      "Epoch [265/500], Loss: 6.0596\n",
      "Epoch [270/500], Loss: 6.1173\n",
      "Epoch [275/500], Loss: 6.0807\n",
      "Epoch [280/500], Loss: 6.0532\n",
      "Epoch [285/500], Loss: 6.0539\n",
      "Epoch [290/500], Loss: 6.2642\n",
      "Epoch [295/500], Loss: 6.0703\n",
      "Epoch [300/500], Loss: 6.0265\n",
      "Epoch [305/500], Loss: 6.0458\n",
      "Epoch [310/500], Loss: 5.9962\n",
      "Epoch [315/500], Loss: 6.0044\n",
      "Epoch [320/500], Loss: 5.9344\n",
      "Epoch [325/500], Loss: 5.9313\n",
      "Epoch [330/500], Loss: 6.1809\n",
      "Epoch [335/500], Loss: 6.4482\n",
      "Epoch [340/500], Loss: 6.3901\n",
      "Epoch [345/500], Loss: 6.3270\n",
      "Epoch [350/500], Loss: 6.2004\n",
      "Epoch [355/500], Loss: 6.1160\n",
      "Epoch [360/500], Loss: 6.1470\n",
      "Epoch [365/500], Loss: 6.0690\n",
      "Epoch [370/500], Loss: 6.0816\n",
      "Epoch [375/500], Loss: 6.1665\n",
      "Epoch [380/500], Loss: 6.0864\n",
      "Epoch [385/500], Loss: 6.0978\n",
      "Epoch [390/500], Loss: 6.0888\n",
      "Epoch [395/500], Loss: 6.0507\n",
      "Epoch [400/500], Loss: 6.0343\n",
      "Epoch [405/500], Loss: 6.0143\n",
      "Epoch [410/500], Loss: 6.0083\n",
      "Epoch [415/500], Loss: 5.9887\n",
      "Epoch [420/500], Loss: 6.0019\n",
      "Epoch [425/500], Loss: 5.9550\n",
      "Epoch [430/500], Loss: 5.9584\n",
      "Epoch [435/500], Loss: 5.8914\n",
      "Epoch [440/500], Loss: 5.9788\n",
      "Epoch [445/500], Loss: 5.9690\n",
      "Epoch [450/500], Loss: 6.0721\n",
      "Epoch [455/500], Loss: 6.0024\n",
      "Epoch [460/500], Loss: 6.3361\n",
      "Epoch [465/500], Loss: 6.0833\n",
      "Epoch [470/500], Loss: 5.9208\n",
      "Epoch [475/500], Loss: 6.0138\n",
      "Epoch [480/500], Loss: 6.0133\n",
      "Epoch [485/500], Loss: 6.0875\n",
      "Epoch [490/500], Loss: 6.0124\n",
      "Epoch [495/500], Loss: 6.1595\n",
      "Epoch [500/500], Loss: 6.2290\n"
     ]
    }
   ],
   "source": [
    "model = models.Attention_512(n_factor=11)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    reconstructed = model(input1, input2, 506)\n",
    "    loss = pearson_correlation_coefficient_loss_function(reconstructed)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
