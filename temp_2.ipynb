{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2806,"status":"ok","timestamp":1692951065007,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"7QwMG7hpTB_k","outputId":"ffcf498f-357b-4ea3-e7c5-2cdb92f19de5"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# import os\n","# os.chdir('/content/drive/MyDrive/work_space/Project/ABFR')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1762,"status":"ok","timestamp":1692951066764,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"B5i89UMJS8sv"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from util.module import *\n","import torch.optim as optim\n","\n","df = pd.read_csv('./Data/house-prices-advanced-regression-techniques/train.csv')\n","numeric_df = df.select_dtypes(include=['int', 'float'])"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1692951066765,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"ixGq1PVeS8s0"},"outputs":[],"source":["numeric_df = numeric_df.dropna(axis=0)\n","numeric_df.reset_index(inplace=True, drop=True)\n","test_df = numeric_df.iloc[:, 1:23]\n","\n","array_df = np.array(test_df)\n","array_df = np.round(array_df, 3)\n","\n","fa = Factor_attention(array_df)\n","fa.col_to_vec(threshold = 0.5)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"element 0 of tensors does not require grad and does not have a grad_fn","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m outputs \u001b[39m=\u001b[39m model(fa)\n\u001b[0;32m      9\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs)\n\u001b[1;32m---> 10\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n","File \u001b[1;32mc:\\Users\\Jang\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n","File \u001b[1;32mc:\\Users\\Jang\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}],"source":["model = Attention(n_factor= fa.n_factors, info_dim = fa.dim_info)\n","criterion = min_relation\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","# 모델 학습\n","for epoch in range(100):\n","    optimizer.zero_grad()\n","    outputs = model(fa)\n","    loss = criterion(outputs)\n","    loss.backward()\n","    optimizer.step()\n","    \n","    # # 검증 데이터를 사용하여 손실 계산\n","    # validation_loss = 0.0\n","    # with torch.no_grad():\n","    #     val_outputs = model(val_inputs)\n","    #     val_loss = criterion(val_outputs, val_labels)\n","    #     validation_loss += val_loss.item()\n","    \n","    # # 검증 손실이 이전 최소 손실보다 작으면 모델 저장 및 기다린 에폭 초기화\n","    # if validation_loss < best_loss:\n","    #     torch.save(model.state_dict(), 'best_model.pth')\n","    #     best_loss = validation_loss\n","    #     current_patience = 0\n","    # else:\n","    #     current_patience += 1\n","    \n","    # # 현재 기다린 에폭이 기다리는 최대 에폭 수보다 크면 학습 종료\n","    # if current_patience >= patience:\n","    #     print(f'조기 종료: 검증 손실이 {patience} 에폭 동안 개선되지 않았습니다.')\n","    #     break\n","\n","# 모델 평가\n","# model.load_state_dict(torch.load('best_model.pth'))\n","\n","# correct = 0\n","# total = 0\n","# with torch.no_grad():\n","#     for batch_inputs, batch_labels in test_dataloader:\n","#         outputs = model(batch_inputs)\n","#         _, predicted = torch.max(outputs.data, 1)\n","#         total += batch_labels.size(0)\n","#         correct += (predicted == batch_labels).sum().item()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"langchain","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
