{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66822,"status":"ok","timestamp":1694578081322,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"7QwMG7hpTB_k","outputId":"42678991-7dc6-442c-c5ed-b1bc7d0fd3d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/drive/MyDrive/work_space/Project/ABFR')\n","!pip install factor_analyzer"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1694579246134,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"B5i89UMJS8sv"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from util.module import *\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","df = pd.read_csv('./Data/house-prices-advanced-regression-techniques/train.csv')\n","numeric_df = df.select_dtypes(include=['int', 'float'])"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1694579247318,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"ixGq1PVeS8s0"},"outputs":[],"source":["numeric_df = numeric_df.dropna(axis=0)\n","numeric_df.reset_index(inplace=True, drop=True)\n","test_df = numeric_df.iloc[:, 1:23]\n","\n","array_df = np.array(test_df)\n","array_df = np.round(array_df, 3)\n","\n","fa = Factor_attention(array_df)\n","fa.col_to_vec(threshold = 0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQ29VuwO4FKH"},"outputs":[],"source":["model = Attention(n_factor= fa.n_factors, info_dim = fa.dim_info)\n","model(fa)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":737,"status":"ok","timestamp":1694578269336,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"Z7vJiLmN4FKM"},"outputs":[],"source":["model = Attention(n_factor= fa.n_factors, info_dim = fa.dim_info)\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","# 모델 학습\n","for epoch in range(100):\n","    optimizer.zero_grad()\n","    outputs = model(fa)\n","    loss = criterion(outputs, model(fa))\n","    loss.backward()\n","    optimizer.step()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1694578389052,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"kxnTk78O4FKP"},"outputs":[],"source":["class FactorAnalysis(nn.Module):\n","    def __init__(self, num_vars, num_factors):\n","        super(FactorAnalysis, self).__init__()\n","        self.loadings = nn.Parameter(torch.randn(num_vars, num_factors).double())\n","        self.psi = nn.Parameter(torch.ones(num_vars).double())  # Uniquenesses, or specific variances\n","\n","    def forward(self):\n","        # Reconstruct covariance matrix based on FA\n","        return torch.mm(self.loadings, self.loadings.t()) + torch.diag(self.psi)\n","\n","def em_step(model, data):\n","    data = data.double()\n","    # Covariance matrix\n","    S = torch.mm(data.t(), data) / data.shape[0]\n","\n","    # E-step\n","    L_psi_inv = torch.mm(model.loadings.t(), torch.inverse(torch.diag(model.psi)))\n","    M = torch.inverse(torch.eye(model.loadings.shape[1]) + torch.mm(L_psi_inv, model.loadings))\n","    E_h = torch.mm(torch.mm(M, model.loadings.t()), torch.inverse(torch.diag(model.psi)))\n","    E_hhT = M + torch.mm(E_h, torch.mm(data.t(), data))\n","\n","    # M-step\n","    model.loadings.data = torch.mm(torch.mm(S, E_h.t()), torch.inverse(E_hhT))\n","    psi_diag = torch.diag(S - torch.mm(model.loadings, torch.mm(E_h, S)))\n","    model.psi.data = psi_diag / data.shape[0]\n","\n","data = model(fa)\n","\n","fa_model = FactorAnalysis(data.shape[-1], data.shape[-1])\n","\n","# num_epochs = 100\n","# for epoch in range(num_epochs):\n","#     em_step(fa_model, data)\n","#     if (epoch + 1) % 10 == 0:\n","#         loss = torch.norm(data - fa_model())\n","#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"executionInfo":{"elapsed":6,"status":"error","timestamp":1694564522832,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"9aUEzVds6pJ0","outputId":"694613ba-b41c-47ab-b820-6aac49432582"},"outputs":[{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-187a0b643e95>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mem_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfa_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1121) must match the size of tensor b (12) at non-singleton dimension 0"]}],"source":["class FactorAnalysis(nn.Module):\n","    def __init__(self, num_vars, num_factors):\n","        super(FactorAnalysis, self).__init__()\n","        self.loadings = nn.Parameter(torch.randn(num_vars, num_factors).float())\n","        self.psi = nn.Parameter(torch.ones(num_vars).float())  # Uniquenesses, or specific variances\n","\n","    def forward(self):\n","        # Reconstruct covariance matrix based on FA\n","        return torch.mm(self.loadings, self.loadings.t()) + torch.diag(self.psi)\n","\n","def em_step(model, data):\n","    # Ensure data is float type\n","    data = data.float()\n","\n","    # Covariance matrix\n","    S = torch.mm(data.t(), data) / data.shape[0]\n","\n","    # E-step\n","    L_psi_inv = torch.mm(model.loadings.t(), torch.inverse(torch.diag(model.psi)))\n","    M = torch.inverse(torch.eye(model.loadings.shape[1]) + torch.mm(L_psi_inv, model.loadings))\n","    E_h = torch.mm(torch.mm(M, model.loadings.t()), torch.inverse(torch.diag(model.psi)))\n","    E_hhT = M + torch.mm(E_h, torch.mm(data.t(), data))\n","\n","    # M-step\n","    model.loadings.data = torch.mm(torch.mm(S, E_h.t()), torch.inverse(E_hhT))\n","    psi_diag = torch.diag(S - torch.mm(model.loadings, torch.mm(E_h, S)))\n","    model.psi.data = psi_diag / data.shape[0]\n","\n","data = model(fa).float()  # Ensure data is of float type\n","\n","fa_model = FactorAnalysis(data.shape[-1], data.shape[-1])\n","\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    em_step(fa_model, data)\n","    if (epoch + 1) % 10 == 0:\n","        loss = torch.norm(data - fa_model())\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1694579783396,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"P1V0Fzgb0wkh"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1694580480509,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"DCBFyQB84FKQ","outputId":"2b699e1d-5362-4df6-d1ca-aaf4178e5285"},"outputs":[{"data":{"text/plain":["tensor([[ 1.0000,  0.9439, -0.1601,  0.9936,  0.8095, -0.9797,  0.9911,  0.9158,\n","          0.0190,  0.9236, -0.3323,  0.4235],\n","        [ 0.9439,  1.0000, -0.4769,  0.9751,  0.5704, -0.8590,  0.9794,  0.9970,\n","         -0.3119,  0.9984, -0.6238,  0.1005],\n","        [-0.1601, -0.4769,  1.0000, -0.2702,  0.4498, -0.0404, -0.2897, -0.5429,\n","          0.9838, -0.5259,  0.9826,  0.8261],\n","        [ 0.9936,  0.9751, -0.2702,  1.0000,  0.7383, -0.9511,  0.9998,  0.9552,\n","         -0.0936,  0.9610, -0.4357,  0.3186],\n","        [ 0.8095,  0.5704,  0.4498,  0.7383,  1.0000, -0.9105,  0.7245,  0.5058,\n","          0.6024,  0.5230,  0.2842,  0.8741],\n","        [-0.9797, -0.8590, -0.0404, -0.9511, -0.9105,  1.0000, -0.9446, -0.8171,\n","         -0.2186, -0.8286,  0.1365, -0.5954],\n","        [ 0.9911,  0.9794, -0.2897,  0.9998,  0.7245, -0.9446,  1.0000,  0.9610,\n","         -0.1137,  0.9664, -0.4538,  0.2993],\n","        [ 0.9158,  0.9970, -0.5429,  0.9552,  0.5058, -0.8171,  0.9610,  1.0000,\n","         -0.3839,  0.9998, -0.6820,  0.0241],\n","        [ 0.0190, -0.3119,  0.9838, -0.0936,  0.6024, -0.2186, -0.1137, -0.3839,\n","          1.0000, -0.3651,  0.9356,  0.9131],\n","        [ 0.9236,  0.9984, -0.5259,  0.9610,  0.5230, -0.8286,  0.9664,  0.9998,\n","         -0.3651,  1.0000, -0.6667,  0.0440],\n","        [-0.3323, -0.6238,  0.9826, -0.4357,  0.2842,  0.1365, -0.4538, -0.6820,\n","          0.9356, -0.6667,  1.0000,  0.7105],\n","        [ 0.4235,  0.1005,  0.8261,  0.3186,  0.8741, -0.5954,  0.2993,  0.0241,\n","          0.9131,  0.0440,  0.7105,  1.0000]], grad_fn=<CopySlices>)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# Helper functions for EM-based FA\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def e_step(X, loadings, unique_variances):\n","    \"\"\"\n","    E-step of the EM algorithm for FA.\n","    \"\"\"\n","    X, loadings, unique_variances = X.double(), loadings.double(), unique_variances.double()\n","\n","    inv_diag_unique_variances = 1.0 / unique_variances\n","    inv_sigma = torch.diag(inv_diag_unique_variances) - torch.mm(\n","        torch.mm(loadings.t(), torch.diag(inv_diag_unique_variances)),\n","        torch.mm(loadings, torch.inverse(torch.eye(loadings.shape[1], device=device, dtype=torch.double) +\n","                                         torch.mm(loadings.t(), torch.mm(torch.diag(inv_diag_unique_variances), loadings))))\n","    )\n","\n","    latent_mean = torch.mm(torch.mm(X, torch.diag(inv_diag_unique_variances)), torch.mm(loadings, inv_sigma))\n","\n","    latent_covariance = torch.eye(loadings.shape[1], device=device, dtype=torch.double) - torch.mm(\n","        torch.mm(loadings.t(), torch.diag(inv_diag_unique_variances)),\n","        torch.mm(loadings, inv_sigma)\n","    ) + torch.mm(inv_sigma, torch.mm(latent_mean.t(), latent_mean))\n","\n","    return latent_mean, latent_covariance\n","\n","def m_step(X, latent_mean, latent_covariance):\n","    \"\"\"\n","    M-step of the EM algorithm for FA.\n","    \"\"\"\n","    X, latent_mean, latent_covariance = X.double(), latent_mean.double(), latent_covariance.double()\n","\n","    loadings = torch.mm(torch.mm(X.t(), latent_mean), torch.inverse(latent_covariance))\n","\n","    diag_residual = torch.diag(torch.mm(X.t(), X)) - torch.diag(torch.mm(loadings, torch.mm(latent_mean.t(), X)))\n","    unique_variances = diag_residual / X.shape[0]\n","\n","    return loadings, unique_variances\n","\n","def em_factor_analysis(X, n_components, max_iter=100):\n","    \"\"\"\n","    Factor Analysis using the EM algorithm.\n","    \"\"\"\n","    n_features = X.shape[1]\n","\n","    # Initialize parameters\n","    loadings = torch.randn(n_features, n_components, device=device, dtype=torch.double)\n","    unique_variances = torch.ones(n_features, device=device, dtype=torch.double)\n","\n","    for i in range(max_iter):\n","        # E-step\n","        latent_mean, latent_covariance = e_step(X, loadings, unique_variances)\n","\n","        # M-step\n","        loadings, unique_variances = m_step(X, latent_mean, latent_covariance)\n","\n","    return loadings, unique_variances\n","\n","def varimax_rotation(loadings, gamma=1.0, max_iter=25, tolerance=1e-6):\n","    \"\"\"\n","    Apply Varimax rotation to the loadings matrix.\n","    \"\"\"\n","    loadings = loadings.double()\n","\n","    n, m = loadings.shape\n","    rotated_loadings = loadings.clone()\n","    rotation_matrix = torch.eye(m, device=device, dtype=torch.double)\n","\n","    for _ in range(max_iter):\n","        d = torch.mm(rotated_loadings, torch.mm(torch.diag(torch.sum(rotated_loadings ** 2, dim=0) ** (-gamma/2)), rotated_loadings.t()))\n","        u, s, v = torch.svd(torch.mm(d, rotated_loadings - (1.0 / n) * torch.mm(rotated_loadings, torch.diag(torch.sum(rotated_loadings, dim=0)))))\n","        rotation_matrix_new = torch.mm(u, v)\n","        rotated_loadings = torch.mm(loadings, rotation_matrix_new)\n","\n","        if torch.norm(rotation_matrix_new - rotation_matrix) < tolerance:\n","            break\n","\n","        rotation_matrix = rotation_matrix_new\n","\n","    return rotated_loadings\n","\n","def cosine_similarity_loss(loadings):\n","    similarity_matrix = F.cosine_similarity(loadings.unsqueeze(0), loadings.unsqueeze(1), dim=2)\n","    loss = torch.mean(similarity_matrix)  # 평균 Cosine Similarity\n","    return similarity_matrix\n","\n","def cosine_similarity_matrix(tensor):\n","    n, m = tensor.shape\n","    if n != m:\n","        raise ValueError(\"The input tensor must be square (n x n).\")\n","\n","    result = torch.zeros((n, n))\n","\n","    for i in range(n):\n","        for j in range(n):\n","            result[i][j] = F.cosine_similarity(tensor[i], tensor[j], dim=0)\n","\n","    return result\n","\n","# Apply EM-based FA and Varimax rotation\n","loadings, unique_variances = em_factor_analysis(model(fa), model(fa).shape[-1], max_iter=25)\n","rotated_loadings = varimax_rotation(loadings)\n","\n","rotated_loadings.shape\n","cosine_similarity_matrix(rotated_loadings)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1694579641000,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"rs2uFHcIx8v5","outputId":"b197b772-166f-4e2d-b6bd-e498a8144d8a"},"outputs":[{"data":{"text/plain":["tensor([[ 1.7742e+02, -4.9488e+02, -4.6031e+02,  5.6740e+01,  7.5120e+02,\n","         -2.3598e+02,  1.8599e+02, -2.8121e+02, -1.1097e+03, -9.7874e+02,\n","         -4.4764e+02, -1.6516e+02],\n","        [-6.5418e+03,  1.5266e+04,  1.4191e+04, -1.2511e+03, -2.3549e+04,\n","          7.4080e+03, -6.4431e+03,  1.0177e+04,  3.5688e+04,  2.9545e+04,\n","          1.3144e+04,  6.6798e+03],\n","        [ 1.5790e+01, -4.6703e+01, -4.3250e+01,  6.1210e+00,  7.0157e+01,\n","         -2.1784e+01,  1.6115e+01, -2.4151e+01, -1.0312e+02, -9.2683e+01,\n","         -4.2924e+01, -1.2877e+01],\n","        [-5.6695e+02,  1.2235e+03,  1.1156e+03, -1.1396e+02, -1.8599e+03,\n","          5.5942e+02, -4.6077e+02,  7.6539e+02,  2.8869e+03,  2.3152e+03,\n","          1.0361e+03,  4.6261e+02],\n","        [ 9.3519e+01,  9.1951e+01,  1.2387e+02, -1.0310e+01, -1.6954e+02,\n","          9.7813e+01, -9.9344e+01,  6.8434e+01,  9.0115e+01,  3.0623e+02,\n","          1.4574e+02,  8.2763e+01],\n","        [ 3.0886e+03, -5.6365e+03, -5.2618e+03,  1.0183e+02,  8.9873e+03,\n","         -2.8681e+03,  2.9389e+03, -4.8519e+03, -1.4138e+04, -1.0538e+04,\n","         -4.4218e+03, -3.6481e+03],\n","        [-1.7699e+03,  3.9429e+03,  3.6012e+03, -3.8540e+02, -5.9846e+03,\n","          1.8060e+03, -1.4683e+03,  2.4143e+03,  9.2333e+03,  7.5022e+03,\n","          3.3722e+03,  1.4407e+03],\n","        [-8.6356e+03,  1.8523e+04,  1.7170e+04, -1.2591e+03, -2.8732e+04,\n","          8.9925e+03, -8.1116e+03,  1.3108e+04,  4.4189e+04,  3.5371e+04,\n","          1.5532e+04,  8.8673e+03],\n","        [-3.6671e+02, -3.5077e+01, -1.6573e+02, -2.5341e+01,  1.7909e+02,\n","         -2.1206e+02,  2.7910e+02, -1.6237e+02,  2.4247e+02, -4.6528e+02,\n","         -2.1144e+02, -2.8384e+02],\n","        [-6.7973e+03,  1.6221e+04,  1.5157e+04, -1.2812e+03, -2.5119e+04,\n","          7.9941e+03, -7.0427e+03,  1.0991e+04,  3.7822e+04,  3.1581e+04,\n","          1.4028e+04,  7.3553e+03],\n","        [-3.6080e+00, -6.2200e-01, -3.9100e-01,  2.2010e+00, -8.3200e-01,\n","          5.6400e-01, -3.1420e+00,  6.1490e+00,  4.1350e+00, -3.2820e+00,\n","         -3.0420e+00,  6.8510e+00],\n","        [ 3.6370e+00, -8.9070e+00, -8.2240e+00,  9.0600e-01,  1.3560e+01,\n","         -4.1930e+00,  3.4080e+00, -5.3830e+00, -2.0488e+01, -1.7272e+01,\n","         -7.8050e+00, -3.2570e+00]], dtype=torch.float64,\n","       grad_fn=<DivBackward0>)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["rotated_loadings = torch.round(rotated_loadings * 1e3) / 1e3\n","rotated_loadings"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":451,"status":"ok","timestamp":1694580496927,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"S01wgN0E1X4f","outputId":"ea15a74f-abac-4ab0-e3ed-886a89dd2c6b"},"outputs":[{"data":{"text/plain":["tensor([[ 1.0000,  0.9965,  0.9870,  0.9922,  0.9887,  0.9972,  0.9973,  0.9970,\n","          0.9887,  0.7415, -0.0455,  0.9865,  0.9925,  0.9724,  0.5537,  0.9883,\n","          0.8638, -0.1356,  0.9773,  0.9933,  0.9980,  0.9972],\n","        [ 0.9965,  1.0000,  0.9940,  0.9986,  0.9826,  0.9988,  0.9987,  0.9883,\n","          0.9952,  0.6963,  0.0099,  0.9955,  0.9990,  0.9756,  0.5907,  0.9945,\n","          0.8910, -0.1905,  0.9898,  0.9872,  0.9961,  0.9990],\n","        [ 0.9870,  0.9940,  1.0000,  0.9980,  0.9572,  0.9875,  0.9871,  0.9810,\n","          0.9960,  0.6247,  0.0821,  0.9988,  0.9972,  0.9915,  0.6740,  0.9998,\n","          0.9331, -0.2908,  0.9976,  0.9876,  0.9813,  0.9881],\n","        [ 0.9922,  0.9986,  0.9980,  1.0000,  0.9714,  0.9949,  0.9946,  0.9840,\n","          0.9961,  0.6581,  0.0572,  0.9991,  0.9999,  0.9831,  0.6319,  0.9983,\n","          0.9128, -0.2419,  0.9958,  0.9865,  0.9902,  0.9952],\n","        [ 0.9887,  0.9826,  0.9572,  0.9714,  1.0000,  0.9904,  0.9908,  0.9807,\n","          0.9672,  0.8132, -0.1397,  0.9609,  0.9734,  0.9268,  0.4316,  0.9590,\n","          0.7921, -0.0052,  0.9466,  0.9668,  0.9948,  0.9898],\n","        [ 0.9972,  0.9988,  0.9875,  0.9949,  0.9904,  1.0000,  1.0000,  0.9885,\n","          0.9911,  0.7275, -0.0262,  0.9899,  0.9957,  0.9651,  0.5505,  0.9883,\n","          0.8682, -0.1434,  0.9821,  0.9839,  0.9990,  1.0000],\n","        [ 0.9973,  0.9987,  0.9871,  0.9946,  0.9908,  1.0000,  1.0000,  0.9886,\n","          0.9907,  0.7294, -0.0284,  0.9895,  0.9954,  0.9645,  0.5482,  0.9879,\n","          0.8667, -0.1405,  0.9815,  0.9838,  0.9991,  1.0000],\n","        [ 0.9970,  0.9883,  0.9810,  0.9840,  0.9807,  0.9885,  0.9886,  1.0000,\n","          0.9801,  0.7494, -0.0582,  0.9776,  0.9836,  0.9751,  0.5566,  0.9830,\n","          0.8552, -0.1298,  0.9671,  0.9975,  0.9909,  0.9884],\n","        [ 0.9887,  0.9952,  0.9960,  0.9961,  0.9672,  0.9911,  0.9907,  0.9801,\n","          1.0000,  0.6554,  0.0113,  0.9949,  0.9961,  0.9794,  0.6334,  0.9945,\n","          0.9177, -0.2467,  0.9923,  0.9827,  0.9856,  0.9915],\n","        [ 0.7415,  0.6963,  0.6247,  0.6581,  0.8132,  0.7275,  0.7294,  0.7494,\n","          0.6554,  1.0000, -0.6045,  0.6262,  0.6629,  0.5845, -0.1273,  0.6305,\n","          0.3083,  0.5575,  0.5869,  0.7033,  0.7557,  0.7248],\n","        [-0.0455,  0.0099,  0.0821,  0.0572, -0.1397, -0.0262, -0.0284, -0.0582,\n","          0.0113, -0.6045,  1.0000,  0.0947,  0.0511,  0.1270,  0.6299,  0.0862,\n","          0.3346, -0.7935,  0.1326, -0.0045, -0.0570, -0.0231],\n","        [ 0.9865,  0.9955,  0.9988,  0.9991,  0.9609,  0.9899,  0.9895,  0.9776,\n","          0.9949,  0.6262,  0.0947,  1.0000,  0.9988,  0.9858,  0.6614,  0.9989,\n","          0.9279, -0.2812,  0.9987,  0.9828,  0.9836,  0.9905],\n","        [ 0.9925,  0.9990,  0.9972,  0.9999,  0.9734,  0.9957,  0.9954,  0.9836,\n","          0.9961,  0.6629,  0.0511,  0.9988,  1.0000,  0.9809,  0.6245,  0.9975,\n","          0.9095, -0.2341,  0.9952,  0.9855,  0.9912,  0.9961],\n","        [ 0.9724,  0.9756,  0.9915,  0.9831,  0.9268,  0.9651,  0.9645,  0.9751,\n","          0.9794,  0.5845,  0.1270,  0.9858,  0.9809,  1.0000,  0.7268,  0.9920,\n","          0.9433, -0.3458,  0.9859,  0.9879,  0.9590,  0.9659],\n","        [ 0.5537,  0.5907,  0.6740,  0.6319,  0.4316,  0.5505,  0.5482,  0.5566,\n","          0.6334, -0.1273,  0.6299,  0.6614,  0.6245,  0.7268,  1.0000,  0.6695,\n","          0.8844, -0.8919,  0.6939,  0.6128,  0.5204,  0.5537],\n","        [ 0.9883,  0.9945,  0.9998,  0.9983,  0.9590,  0.9883,  0.9879,  0.9830,\n","          0.9945,  0.6305,  0.0862,  0.9989,  0.9975,  0.9920,  0.6695,  1.0000,\n","          0.9290, -0.2835,  0.9971,  0.9892,  0.9827,  0.9888],\n","        [ 0.8638,  0.8910,  0.9331,  0.9128,  0.7921,  0.8682,  0.8667,  0.8552,\n","          0.9177,  0.3083,  0.3346,  0.9279,  0.9095,  0.9433,  0.8844,  0.9290,\n","          1.0000, -0.6113,  0.9443,  0.8849,  0.8478,  0.8701],\n","        [-0.1356, -0.1905, -0.2908, -0.2419, -0.0052, -0.1434, -0.1405, -0.1298,\n","         -0.2467,  0.5575, -0.7935, -0.2812, -0.2341, -0.3458, -0.8919, -0.2835,\n","         -0.6113,  1.0000, -0.3270, -0.1964, -0.1042, -0.1473],\n","        [ 0.9773,  0.9898,  0.9976,  0.9958,  0.9466,  0.9821,  0.9815,  0.9671,\n","          0.9923,  0.5869,  0.1326,  0.9987,  0.9952,  0.9859,  0.6939,  0.9971,\n","          0.9443, -0.3270,  1.0000,  0.9753,  0.9736,  0.9828],\n","        [ 0.9933,  0.9872,  0.9876,  0.9865,  0.9668,  0.9839,  0.9838,  0.9975,\n","          0.9827,  0.7033, -0.0045,  0.9828,  0.9855,  0.9879,  0.6128,  0.9892,\n","          0.8849, -0.1964,  0.9753,  1.0000,  0.9840,  0.9841],\n","        [ 0.9980,  0.9961,  0.9813,  0.9902,  0.9948,  0.9990,  0.9991,  0.9909,\n","          0.9856,  0.7557, -0.0570,  0.9836,  0.9912,  0.9590,  0.5204,  0.9827,\n","          0.8478, -0.1042,  0.9736,  0.9840,  1.0000,  0.9988],\n","        [ 0.9972,  0.9990,  0.9881,  0.9952,  0.9898,  1.0000,  1.0000,  0.9884,\n","          0.9915,  0.7248, -0.0231,  0.9905,  0.9961,  0.9659,  0.5537,  0.9888,\n","          0.8701, -0.1473,  0.9828,  0.9841,  0.9988,  1.0000]])"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["tensor_df = torch.Tensor(array_df).double()\n","loadings, unique_variances = em_factor_analysis(tensor_df, tensor_df.shape[-1], max_iter=25)\n","rotated_loadings = varimax_rotation(loadings)\n","\n","rotated_loadings.shape\n","cosine_similarity_matrix(rotated_loadings)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1694578977325,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"vk9dREei4FKR"},"outputs":[],"source":["class TorchFactorAnalysis:\n","    def __init__(self):\n","        self.loadings = None\n","        self.rotation_matrix = None\n","        self.rotated_loadings = None\n","        self.factor_score = None\n","        self.factor_score_coefficent = None\n","        self.cov_mat = None\n","        self.explained_variance = None\n","\n","    def fit(self, X, num_factor=2, rotation_type='varimax', k=4, max_iter=1000, eps=1e-05):\n","        assert rotation_type in ['varimax', 'promax']\n","\n","        self.get_loadings(X, num_factor)\n","        L = self.loadings\n","\n","        self.get_rotated_loadings(L, rotation_type=rotation_type,\n","                                  max_iter=max_iter, eps=eps, k=k)\n","\n","        self.get_factor_score(X)\n","        return self\n","\n","    def get_rotated_loadings(self, L, rotation_type, k, max_iter, eps):\n","        if rotation_type == 'varimax':\n","            R, rotated_L = self._varimax(L, max_iter=max_iter, eps=eps)\n","            self.rotation_matrix = R\n","            self.rotated_loadings = rotated_L\n","        else:\n","            R, rotated_L = self._promax(L, k=k, max_iter=max_iter, eps=eps)\n","            self.rotation_matrix = R\n","            self.rotated_loadings = rotated_L\n","\n","    def _varimax(self, L, max_iter=1000, eps=1e-05):\n","        R = torch.eye(L.shape[1], device=device)\n","        d_old = 0\n","        p = L.shape[0]\n","        for i in range(max_iter):\n","            L_star = torch.mm(L, R)\n","            Q = torch.mm(L.T, L_star ** 3 - torch.mm(L_star, torch.diag(torch.diag(torch.mm(L_star.T, L_star)))/p))\n","            U, S, V = torch.svd(Q)\n","            R = torch.mm(U, V.T)\n","            d_new = torch.sum(S)\n","            if d_new < d_old * (1 + eps):\n","                break\n","            else:\n","                d_old = d_new\n","        return R, L_star\n","\n","    def _promax(self, L, k=4, max_iter=1000, eps=1e-5):\n","        _, L_star = self._varimax(L, max_iter=max_iter, eps=eps)\n","        P = L_star * (torch.abs(L_star) ** (k-1))\n","        L_inv = torch.inverse(torch.mm(L_star.T, L_star))\n","        R = torch.mm(torch.mm(L_inv, L_star.T), P)\n","        R = R/torch.sqrt(torch.sum(R ** 2, dim=0))\n","        L_final = torch.mm(L_star, R)\n","        return R, L_final\n","\n","    def get_loadings(self, X, num_factor):\n","        cov_mat = torch.mm((X - torch.mean(X, dim=0)).T, (X - torch.mean(X, dim=0))) / (X.shape[0]-1)\n","        self.cov_mat = cov_mat\n","        eigen_values, eigen_vectors = torch.linalg.eig(cov_mat)\n","        eigen_values = eigen_values[:num_factor, 0]\n","        eigen_vectors = eigen_vectors[:, :num_factor]\n","        loadings = torch.sqrt(eigen_values).unsqueeze(1) * eigen_vectors\n","        self.loadings = loadings\n","        self.explained_variance = torch.sum(eigen_values) / X.shape[1]\n","\n","    def get_factor_score(self, X):\n","        L = self.rotated_loadings\n","        S_inv = torch.inverse(self.cov_mat)\n","        factor_score = torch.mm(torch.mm(L.T, S_inv), (X - torch.mean(X, dim=0)).T)\n","        self.factor_score_coefficent = (torch.mm(L.T, S_inv)).T\n","        self.factor_score = factor_score.T\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":7,"status":"error","timestamp":1694578977642,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"OMVl4MuS4FKS","outputId":"6490c92a-8a72-4d43-cd82-c06d86a054b1"},"outputs":[{"ename":"IndexError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-8b5e0c3443e6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_fa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchFactorAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'promax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-e4a768ceb2d4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, num_factor, rotation_type, k, max_iter, eps)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mrotation_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'varimax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loadings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-e4a768ceb2d4>\u001b[0m in \u001b[0;36mget_loadings\u001b[0;34m(self, X, num_factor)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0meigen_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigen_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0meigen_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigen_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0meigen_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigen_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_factor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mloadings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigen_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meigen_vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"]}],"source":["temp_fa = TorchFactorAnalysis().fit(model(fa), num_factor=model(fa).shape[-1], rotation_type='promax')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWfmfvcZ4FKT"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
