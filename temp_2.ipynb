{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2806,"status":"ok","timestamp":1692951065007,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"7QwMG7hpTB_k","outputId":"ffcf498f-357b-4ea3-e7c5-2cdb92f19de5"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# import os\n","# os.chdir('/content/drive/MyDrive/work_space/Project/ABFR')"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1762,"status":"ok","timestamp":1692951066764,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"B5i89UMJS8sv"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from util.module import *\n","import torch.optim as optim\n","\n","df = pd.read_csv('./Data/house-prices-advanced-regression-techniques/train.csv')\n","numeric_df = df.select_dtypes(include=['int', 'float'])"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1692951066765,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"ixGq1PVeS8s0"},"outputs":[],"source":["numeric_df = numeric_df.dropna(axis=0)\n","numeric_df.reset_index(inplace=True, drop=True)\n","test_df = numeric_df.iloc[:, 1:23]\n","\n","array_df = np.array(test_df)\n","array_df = np.round(array_df, 3)\n","\n","fa = Factor_attention(array_df)\n","fa.col_to_vec(threshold = 0.5)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 6.0000e+01,  4.7895e+03,  5.0000e+00,  ..., -2.9092e+03,\n","          0.0000e+00,  1.0000e+00],\n","        [ 2.0000e+01,  5.0350e+03,  8.0000e+00,  ..., -9.6239e+02,\n","          1.0000e+00,  1.0000e+00],\n","        [ 6.0000e+01,  4.8939e+03,  5.0000e+00,  ..., -2.9907e+03,\n","          0.0000e+00,  1.0000e+00],\n","        ...,\n","        [ 7.0000e+01,  5.3590e+03,  9.0000e+00,  ..., -3.9552e+03,\n","          0.0000e+00,  1.0000e+00],\n","        [ 2.0000e+01,  4.6848e+03,  6.0000e+00,  ..., -8.2216e+02,\n","          0.0000e+00,  1.0000e+00],\n","        [ 2.0000e+01,  5.0077e+03,  6.0000e+00,  ..., -9.5928e+02,\n","          0.0000e+00,  1.0000e+00]], dtype=torch.float64,\n","       grad_fn=<CatBackward0>)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model = Attention(n_factor= fa.n_factors, info_dim = fa.dim_info)\n","model(fa)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["model = Attention(n_factor= fa.n_factors, info_dim = fa.dim_info)\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","# 모델 학습\n","for epoch in range(100):\n","    optimizer.zero_grad()\n","    outputs = model(fa)\n","    loss = criterion(outputs, model(fa))\n","    loss.backward()\n","    optimizer.step()\n","    "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1121, 12])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model(fa).shape"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"inverse: LAPACK library not found in compilation","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[17], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 32\u001b[0m     em_step(fa_model, data)\n\u001b[0;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     34\u001b[0m         loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(data \u001b[39m-\u001b[39m fa_model())\n","Cell \u001b[1;32mIn[17], line 16\u001b[0m, in \u001b[0;36mem_step\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m     13\u001b[0m S \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(data\u001b[39m.\u001b[39mt(), data) \u001b[39m/\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[39m# E-step\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m L_psi_inv \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(model\u001b[39m.\u001b[39mloadings\u001b[39m.\u001b[39mt(), torch\u001b[39m.\u001b[39;49minverse(torch\u001b[39m.\u001b[39;49mdiag(model\u001b[39m.\u001b[39;49mpsi)))\n\u001b[0;32m     17\u001b[0m M \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39minverse(torch\u001b[39m.\u001b[39meye(model\u001b[39m.\u001b[39mloadings\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmm(L_psi_inv, model\u001b[39m.\u001b[39mloadings))\n\u001b[0;32m     18\u001b[0m E_h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(torch\u001b[39m.\u001b[39mmm(M, model\u001b[39m.\u001b[39mloadings\u001b[39m.\u001b[39mt()), torch\u001b[39m.\u001b[39minverse(torch\u001b[39m.\u001b[39mdiag(model\u001b[39m.\u001b[39mpsi)))\n","\u001b[1;31mRuntimeError\u001b[0m: inverse: LAPACK library not found in compilation"]}],"source":["class FactorAnalysis(nn.Module):\n","    def __init__(self, num_vars, num_factors):\n","        super(FactorAnalysis, self).__init__()\n","        self.loadings = nn.Parameter(torch.randn(num_vars, num_factors))\n","        self.psi = nn.Parameter(torch.ones(num_vars))  # Uniquenesses, or specific variances\n","    \n","    def forward(self):\n","        # Reconstruct covariance matrix based on FA\n","        return torch.mm(self.loadings, self.loadings.t()) + torch.diag(self.psi)\n","    \n","def em_step(model, data):\n","    # Covariance matrix\n","    S = torch.mm(data.t(), data) / data.shape[0]\n","    \n","    # E-step\n","    L_psi_inv = torch.mm(model.loadings.t(), torch.inverse(torch.diag(model.psi)))\n","    M = torch.inverse(torch.eye(model.loadings.shape[1]) + torch.mm(L_psi_inv, model.loadings))\n","    E_h = torch.mm(torch.mm(M, model.loadings.t()), torch.inverse(torch.diag(model.psi)))\n","    E_hhT = M + torch.mm(E_h, torch.mm(data.t(), data))\n","    \n","    # M-step\n","    model.loadings.data = torch.mm(torch.mm(S, E_h.t()), torch.inverse(E_hhT))\n","    psi_diag = torch.diag(S - torch.mm(model.loadings, torch.mm(E_h, S)))\n","    model.psi.data = psi_diag / data.shape[0]\n","\n","data = model(fa)\n","\n","fa_model = FactorAnalysis(data.shape[-1], data.shape[-1])\n","\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    em_step(fa_model, data)\n","    if (epoch + 1) % 10 == 0:\n","        loss = torch.norm(data - fa_model())\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"inverse: LAPACK library not found in compilation","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m rotated_loadings\n\u001b[0;32m     74\u001b[0m \u001b[39m# Apply EM-based FA and Varimax rotation\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m loadings, unique_variances \u001b[39m=\u001b[39m em_factor_analysis(model(fa), model(fa)\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], max_iter\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     76\u001b[0m rotated_loadings \u001b[39m=\u001b[39m varimax_rotation(loadings)\n\u001b[0;32m     78\u001b[0m rotated_loadings\n","Cell \u001b[1;32mIn[20], line 47\u001b[0m, in \u001b[0;36mem_factor_analysis\u001b[1;34m(X, n_components, max_iter)\u001b[0m\n\u001b[0;32m     43\u001b[0m unique_variances \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(n_features, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[0;32m     46\u001b[0m     \u001b[39m# E-step\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     latent_mean, latent_covariance \u001b[39m=\u001b[39m e_step(X, loadings, unique_variances)\n\u001b[0;32m     49\u001b[0m     \u001b[39m# M-step\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     loadings, unique_variances \u001b[39m=\u001b[39m m_step(X, latent_mean, latent_covariance)\n","Cell \u001b[1;32mIn[20], line 11\u001b[0m, in \u001b[0;36me_step\u001b[1;34m(X, loadings, unique_variances)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mE-step of the EM algorithm for FA.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m inv_diag_unique_variances \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m unique_variances\n\u001b[0;32m      9\u001b[0m inv_sigma \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdiag(inv_diag_unique_variances) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mmm(\n\u001b[0;32m     10\u001b[0m     torch\u001b[39m.\u001b[39mmm(loadings\u001b[39m.\u001b[39mt(), torch\u001b[39m.\u001b[39mdiag(inv_diag_unique_variances)),\n\u001b[1;32m---> 11\u001b[0m     torch\u001b[39m.\u001b[39mmm(loadings, torch\u001b[39m.\u001b[39;49minverse(torch\u001b[39m.\u001b[39;49meye(loadings\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], device\u001b[39m=\u001b[39;49mdevice) \u001b[39m+\u001b[39;49m \n\u001b[0;32m     12\u001b[0m                                      torch\u001b[39m.\u001b[39;49mmm(loadings\u001b[39m.\u001b[39;49mt(), torch\u001b[39m.\u001b[39;49mmm(torch\u001b[39m.\u001b[39;49mdiag(inv_diag_unique_variances), loadings))))\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m latent_mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(torch\u001b[39m.\u001b[39mmm(X, torch\u001b[39m.\u001b[39mdiag(inv_diag_unique_variances)), torch\u001b[39m.\u001b[39mmm(loadings, inv_sigma))\n\u001b[0;32m     17\u001b[0m latent_covariance \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meye(loadings\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], device\u001b[39m=\u001b[39mdevice) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mmm(\n\u001b[0;32m     18\u001b[0m     torch\u001b[39m.\u001b[39mmm(loadings\u001b[39m.\u001b[39mt(), torch\u001b[39m.\u001b[39mdiag(inv_diag_unique_variances)),\n\u001b[0;32m     19\u001b[0m     torch\u001b[39m.\u001b[39mmm(loadings, inv_sigma)\n\u001b[0;32m     20\u001b[0m ) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmm(inv_sigma, torch\u001b[39m.\u001b[39mmm(latent_mean\u001b[39m.\u001b[39mt(), latent_mean))\n","\u001b[1;31mRuntimeError\u001b[0m: inverse: LAPACK library not found in compilation"]}],"source":["# Helper functions for EM-based FA\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def e_step(X, loadings, unique_variances):\n","    \"\"\"\n","    E-step of the EM algorithm for FA.\n","    \"\"\"\n","    inv_diag_unique_variances = 1.0 / unique_variances\n","    inv_sigma = torch.diag(inv_diag_unique_variances) - torch.mm(\n","        torch.mm(loadings.t(), torch.diag(inv_diag_unique_variances)),\n","        torch.mm(loadings, torch.inverse(torch.eye(loadings.shape[1], device=device) + \n","                                         torch.mm(loadings.t(), torch.mm(torch.diag(inv_diag_unique_variances), loadings))))\n","    )\n","    \n","    latent_mean = torch.mm(torch.mm(X, torch.diag(inv_diag_unique_variances)), torch.mm(loadings, inv_sigma))\n","    \n","    latent_covariance = torch.eye(loadings.shape[1], device=device) - torch.mm(\n","        torch.mm(loadings.t(), torch.diag(inv_diag_unique_variances)),\n","        torch.mm(loadings, inv_sigma)\n","    ) + torch.mm(inv_sigma, torch.mm(latent_mean.t(), latent_mean))\n","    \n","    return latent_mean, latent_covariance\n","\n","def m_step(X, latent_mean, latent_covariance):\n","    \"\"\"\n","    M-step of the EM algorithm for FA.\n","    \"\"\"\n","    loadings = torch.mm(torch.mm(X.t(), latent_mean), torch.inverse(latent_covariance))\n","    \n","    diag_residual = torch.diag(torch.mm(X.t(), X)) - torch.diag(torch.mm(loadings, torch.mm(latent_mean.t(), X)))\n","    unique_variances = diag_residual / X.shape[0]\n","    \n","    return loadings, unique_variances\n","\n","def em_factor_analysis(X, n_components, max_iter=100):\n","    \"\"\"\n","    Factor Analysis using the EM algorithm.\n","    \"\"\"\n","    n_features = X.shape[1]\n","    \n","    # Initialize parameters\n","    loadings = torch.randn(n_features, n_components, device=device)\n","    unique_variances = torch.ones(n_features, device=device)\n","    \n","    for i in range(max_iter):\n","        # E-step\n","        latent_mean, latent_covariance = e_step(X, loadings, unique_variances)\n","        \n","        # M-step\n","        loadings, unique_variances = m_step(X, latent_mean, latent_covariance)\n","    \n","    return loadings, unique_variances\n","def varimax_rotation(loadings, gamma=1.0, max_iter=100, tolerance=1e-6):\n","    \"\"\"\n","    Apply Varimax rotation to the loadings matrix.\n","    \"\"\"\n","    n, m = loadings.shape\n","    rotated_loadings = loadings.clone()\n","    rotation_matrix = torch.eye(m, device=device)\n","    \n","    for _ in range(max_iter):\n","        d = torch.mm(rotated_loadings, torch.mm(torch.diag(torch.sum(rotated_loadings ** 2, dim=0) ** (-gamma/2)), rotated_loadings.t()))\n","        u, s, v = torch.svd(torch.mm(d, rotated_loadings - (1.0 / n) * torch.mm(rotated_loadings, torch.diag(torch.sum(rotated_loadings, dim=0)))))\n","        rotation_matrix_new = torch.mm(u, v)\n","        rotated_loadings = torch.mm(loadings, rotation_matrix_new)\n","        \n","        if torch.norm(rotation_matrix_new - rotation_matrix) < tolerance:\n","            break\n","        \n","        rotation_matrix = rotation_matrix_new\n","    \n","    return rotated_loadings\n","\n","# Apply EM-based FA and Varimax rotation\n","loadings, unique_variances = em_factor_analysis(model(fa), model(fa).shape[-1], max_iter=100)\n","rotated_loadings = varimax_rotation(loadings)\n","\n","rotated_loadings\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["class TorchFactorAnalysis:\n","    def __init__(self):\n","        self.loadings = None\n","        self.rotation_matrix = None\n","        self.rotated_loadings = None\n","        self.factor_score = None\n","        self.factor_score_coefficent = None\n","        self.cov_mat = None\n","        self.explained_variance = None\n","        \n","    def fit(self, X, num_factor=2, rotation_type='varimax', k=4, max_iter=1000, eps=1e-05):\n","        assert rotation_type in ['varimax', 'promax']\n","        \n","        self.get_loadings(X, num_factor)\n","        L = self.loadings\n","        \n","        self.get_rotated_loadings(L, rotation_type=rotation_type, \n","                                  max_iter=max_iter, eps=eps, k=k)\n","        \n","        self.get_factor_score(X)\n","        return self\n","    \n","    def get_rotated_loadings(self, L, rotation_type, k, max_iter, eps):\n","        if rotation_type == 'varimax':\n","            R, rotated_L = self._varimax(L, max_iter=max_iter, eps=eps)\n","            self.rotation_matrix = R\n","            self.rotated_loadings = rotated_L\n","        else:\n","            R, rotated_L = self._promax(L, k=k, max_iter=max_iter, eps=eps)\n","            self.rotation_matrix = R\n","            self.rotated_loadings = rotated_L\n","            \n","    def _varimax(self, L, max_iter=1000, eps=1e-05):\n","        R = torch.eye(L.shape[1], device=device)\n","        d_old = 0 \n","        p = L.shape[0]\n","        for i in range(max_iter):\n","            L_star = torch.mm(L, R)\n","            Q = torch.mm(L.T, L_star ** 3 - torch.mm(L_star, torch.diag(torch.diag(torch.mm(L_star.T, L_star)))/p))\n","            U, S, V = torch.svd(Q)\n","            R = torch.mm(U, V.T)\n","            d_new = torch.sum(S)\n","            if d_new < d_old * (1 + eps):\n","                break\n","            else:\n","                d_old = d_new\n","        return R, L_star        \n","        \n","    def _promax(self, L, k=4, max_iter=1000, eps=1e-5):\n","        _, L_star = self._varimax(L, max_iter=max_iter, eps=eps)\n","        P = L_star * (torch.abs(L_star) ** (k-1))\n","        L_inv = torch.inverse(torch.mm(L_star.T, L_star))\n","        R = torch.mm(torch.mm(L_inv, L_star.T), P)\n","        R = R/torch.sqrt(torch.sum(R ** 2, dim=0))\n","        L_final = torch.mm(L_star, R)\n","        return R, L_final\n","        \n","    def get_loadings(self, X, num_factor):\n","        cov_mat = torch.mm((X - torch.mean(X, dim=0)).T, (X - torch.mean(X, dim=0))) / (X.shape[0]-1)\n","        self.cov_mat = cov_mat\n","        eigen_values, eigen_vectors = torch.eig(cov_mat, eigenvectors=True)\n","        eigen_values = eigen_values[:num_factor, 0]\n","        eigen_vectors = eigen_vectors[:, :num_factor]\n","        loadings = torch.sqrt(eigen_values).unsqueeze(1) * eigen_vectors\n","        self.loadings = loadings\n","        self.explained_variance = torch.sum(eigen_values) / X.shape[1]\n","        \n","    def get_factor_score(self, X):\n","        L = self.rotated_loadings\n","        S_inv = torch.inverse(self.cov_mat)\n","        factor_score = torch.mm(torch.mm(L.T, S_inv), (X - torch.mean(X, dim=0)).T)\n","        self.factor_score_coefficent = (torch.mm(L.T, S_inv)).T\n","        self.factor_score = factor_score.T\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Jang\\AppData\\Local\\Temp\\ipykernel_5480\\3683534337.py:61: UserWarning: torch.eig is deprecated in favor of torch.linalg.eig and will be removed in a future PyTorch release.\n","torch.linalg.eig returns complex tensors of dtype cfloat or cdouble rather than real tensors mimicking complex tensors.\n","L, _ = torch.eig(A)\n","should be replaced with\n","L_complex = torch.linalg.eigvals(A)\n","and\n","L, V = torch.eig(A, eigenvectors=True)\n","should be replaced with\n","L_complex, V_complex = torch.linalg.eig(A) (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:3427.)\n","  eigen_values, eigen_vectors = torch.eig(cov_mat, eigenvectors=True)\n"]},{"ename":"RuntimeError","evalue":"Calling torch.eig on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m temp_fa \u001b[39m=\u001b[39m TorchFactorAnalysis()\u001b[39m.\u001b[39;49mfit(model(fa), num_factor\u001b[39m=\u001b[39;49mmodel(fa)\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], rotation_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpromax\u001b[39;49m\u001b[39m'\u001b[39;49m)\n","Cell \u001b[1;32mIn[21], line 14\u001b[0m, in \u001b[0;36mTorchFactorAnalysis.fit\u001b[1;34m(self, X, num_factor, rotation_type, k, max_iter, eps)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, num_factor\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, rotation_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvarimax\u001b[39m\u001b[39m'\u001b[39m, k\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, eps\u001b[39m=\u001b[39m\u001b[39m1e-05\u001b[39m):\n\u001b[0;32m     12\u001b[0m     \u001b[39massert\u001b[39;00m rotation_type \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mvarimax\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpromax\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_loadings(X, num_factor)\n\u001b[0;32m     15\u001b[0m     L \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloadings\n\u001b[0;32m     17\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_rotated_loadings(L, rotation_type\u001b[39m=\u001b[39mrotation_type, \n\u001b[0;32m     18\u001b[0m                               max_iter\u001b[39m=\u001b[39mmax_iter, eps\u001b[39m=\u001b[39meps, k\u001b[39m=\u001b[39mk)\n","Cell \u001b[1;32mIn[21], line 61\u001b[0m, in \u001b[0;36mTorchFactorAnalysis.get_loadings\u001b[1;34m(self, X, num_factor)\u001b[0m\n\u001b[0;32m     59\u001b[0m cov_mat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm((X \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mmean(X, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mT, (X \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mmean(X, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))) \u001b[39m/\u001b[39m (X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcov_mat \u001b[39m=\u001b[39m cov_mat\n\u001b[1;32m---> 61\u001b[0m eigen_values, eigen_vectors \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49meig(cov_mat, eigenvectors\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     62\u001b[0m eigen_values \u001b[39m=\u001b[39m eigen_values[:num_factor, \u001b[39m0\u001b[39m]\n\u001b[0;32m     63\u001b[0m eigen_vectors \u001b[39m=\u001b[39m eigen_vectors[:, :num_factor]\n","\u001b[1;31mRuntimeError\u001b[0m: Calling torch.eig on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support."]}],"source":["temp_fa = TorchFactorAnalysis().fit(model(fa), num_factor=model(fa).shape[-1], rotation_type='promax')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"langchain","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
